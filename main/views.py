from django.shortcuts import render
from django.conf import settings
from django.utils.safestring import mark_safe
import markdown
import re
import requests
import logging
import traceback
from .prompts.chunking_prompt import generate_prompt
from openai import OpenAI
import os
import google.generativeai as genai

# Configurar o logger
logger = logging.getLogger(__name__)

def test_gemini(request):
    result = None
    error = None
    tema = ""
    num_partes = 2
    html_result = None
    use_gemini_fallback = False  # Mover para fora do bloco POST para evitar o UnboundLocalError
    
    # Verificar se o sistema est√° em modo de manuten√ß√£o (por exemplo, sem cr√©ditos)
    maintenance_mode = os.path.exists(os.path.join(settings.BASE_DIR, 'maintenance_mode'))
    if maintenance_mode:
        error = "O servi√ßo est√° temporariamente indispon√≠vel para manuten√ß√£o. Por favor, tente novamente mais tarde."
        return render(request, 'index.html', {
            'error': error,
            'tema': tema,
            'num_partes': num_partes
        })
    
    try:
        # Configurar ambos os clientes, mas come√ßar com Zuki
        try:
            # Inicializa√ß√£o segura do cliente OpenAI
            client_kwargs = {
                'base_url': "https://api.zukijourney.com/v1",
                'api_key': settings.ZUKI_API_KEY
            }
            # Em ambiente de produ√ß√£o, pode haver proxies sendo injetados automaticamente
            zuki_client = OpenAI(**client_kwargs)
        except TypeError as client_error:
            logger.error(f"Erro ao inicializar cliente OpenAI: {str(client_error)}")
            if 'proxies' in str(client_error):
                # Tenta inicializar sem argumentos extras que possam estar sendo injetados
                zuki_client = None
                # For√ßar o uso do fallback Gemini
                use_gemini_fallback = True
                logger.info("For√ßando uso do fallback devido a erro na inicializa√ß√£o do cliente OpenAI")
            else:
                # Repassar o erro original se for outro tipo de problema
                raise
        
        # Configurar o cliente Gemini (ser√° usado como fallback)
        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
        except Exception as gemini_error:
            logger.error(f"Erro ao configurar Gemini API: {str(gemini_error)}")
            if not zuki_client:
                # Se ambos falharem, n√£o podemos continuar
                error = "Erro na configura√ß√£o dos servi√ßos de IA. Por favor, tente novamente mais tarde."
                return render(request, 'index.html', {
                    'error': error,
                    'tema': tema,
                    'num_partes': num_partes
                })
        
        if request.method == 'POST':
            tema = request.POST.get('tema', '')
            
            # Log do tema recebido para diagn√≥stico
            logger.info(f"Tema recebido: '{tema}' (tamanho: {len(tema)} caracteres)")
            
            # Verificar se o tema √© muito longo
            if (len(tema) > 200):
                error = f"O tema √© muito longo ({len(tema)} caracteres). Por favor, reduza para no m√°ximo 200 caracteres."
                return render(request, 'index.html', {
                    'error': error,
                    'tema': tema,
                    'num_partes': num_partes
                })
                
            try:
                num_partes = int(request.POST.get('num_partes', '2'))
                if num_partes < 2:
                    error = "O n√∫mero de partes deve ser maior que 1."
                    return render(request, 'index.html', {
                        'error': error,
                        'tema': tema,
                        'num_partes': num_partes
                    })
                # Adicionando limite m√°ximo de partes
                if num_partes > 22:
                    error = "O n√∫mero m√°ximo de partes permitido √© 22."
                    return render(request, 'index.html', {
                        'error': error,
                        'tema': tema,
                        'num_partes': 22  # Redefinindo para o m√°ximo permitido
                    })
            except ValueError:
                error = "O n√∫mero de partes deve ser um n√∫mero inteiro v√°lido."
                return render(request, 'index.html', {
                    'error': error,
                    'tema': tema,
                    'num_partes': 2
                })
            
            # Fun√ß√£o para processar com Gemini (fallback)
            def process_with_gemini():
                nonlocal result
                nonlocal use_gemini_fallback  # Importante: acessar a vari√°vel do escopo externo
                nonlocal html_result  # Precisamos acessar html_result tamb√©m
                logger.info("Usando API Gemini como fallback")
                use_gemini_fallback = True  # Atualizar a flag
                
                # Gerar o prompt uma vez
                prompt = generate_prompt(tema, num_partes)
                
                # Configurar o modelo Gemini
                gemini_model = genai.GenerativeModel('gemini-1.5-flash')
                
                # Fazer a requisi√ß√£o ao Gemini
                gemini_response = gemini_model.generate_content(prompt)
                
                # Verificar se a resposta foi gerada com sucesso
                if (gemini_response and hasattr(gemini_response, 'text')):
                    result = gemini_response.text
                    logger.info(f"Resposta recebida do Gemini com {len(result) if result else 0} caracteres")
                    
                    # Converter markdown para HTML logo ap√≥s obter o resultado
                    try:
                        html_result = mark_safe(markdown.markdown(
                            result, 
                            extensions=['extra', 'fenced_code', 'tables', 'nl2br', 'sane_lists']
                        ))
                    except Exception as md_error:
                        logger.error(f"Erro na convers√£o Markdown: {str(md_error)}")
                        raise Exception("Erro ao processar resposta do Gemini")
                else:
                    raise Exception("Resposta inv√°lida do Gemini.")
                
                # Retornar para a view principal com o resultado processado
                context = {
                    'result': result,
                    'html_result': html_result,
                    'error': None,
                    'tema': tema,
                    'num_partes': num_partes,
                    'has_content': bool(html_result),
                    'app_title': 'Chunkify',
                    'used_fallback': use_gemini_fallback
                }
                
                return render(request, 'index.html', context)
            
            # Prepara o prompt baseado no n√∫mero de partes
            if num_partes > 10:
                # Dividir em m√∫ltiplas solicita√ß√µes para temas com muitas partes
                meio = num_partes // 2
                prompt_parte1 = f"""Crie um guia de estudos para o tema "{tema}" detalhando COMPLETAMENTE apenas as partes de 1 at√© {meio}.

Use esta formata√ß√£o:
- Se√ß√µes principais como Heading 1 (#): "# Parte X: [T√≠tulo]" 
- Dentro de cada parte use destaque em negrito:
  - **Objetivo de Aprendizagem:** (1 par√°grafo)
  - **T√≥picos Principais:** (lista de 3-5 itens com descri√ß√µes)
  - **Conceitos-chave:** (lista de termos)
  - **Pergunta de Reflex√£o:** (quest√£o instigante)"""
                
                prompt_parte2 = f"""Crie um guia de estudos para o tema "{tema}" detalhando COMPLETAMENTE apenas as partes de {meio+1} at√© {num_partes}.

Use esta formata√ß√£o:
- Se√ß√µes principais como Heading 1 (#): "# Parte X: [T√≠tulo]" 
- Dentro de cada parte use destaque em negrito:
  - **Objetivo de Aprendizagem:** (1 par√°grafo)
  - **T√≥picos Principais:** (lista de 3-5 itens com descri√ß√µes)
  - **Conceitos-chave:** (lista de termos)
  - **Pergunta de Reflex√£o:** (quest√£o instigante)

Ao final, adicione uma conclus√£o como Heading 1 (# Conclus√£o) que sintetize tudo."""
                
                prompt_parte3 = f"""Crie a introdu√ß√£o para um guia de estudos para o tema "{tema}" em {num_partes} partes.
Use esta formata√ß√£o:
- T√≠tulo principal como Heading 2 (##): "## {tema} em {num_partes} Partes"
- Subse√ß√µes como Heading 2 (##):
  - ## Contextualiza√ß√£o (2-3 par√°grafos)
  - ## Objetivos Gerais (4-5 compet√™ncias em lista)"""
                
                try:
                    if use_gemini_fallback or not zuki_client:
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    else:
                        # Gerar as tr√™s partes usando Zuki
                        response1 = zuki_client.chat.completions.create(
                            model="gemini-2.0-flash-thinking-exp-01-21",
                            messages=[{"role": "user", "content": prompt_parte1}],
                            max_tokens=4096,
                            temperature=0.7
                        )
                        
                        response2 = zuki_client.chat.completions.create(
                            model="gemini-2.0-flash-thinking-exp-01-21",
                            messages=[{"role": "user", "content": prompt_parte2}],
                            max_tokens=4096,
                            temperature=0.7
                        )
                        
                        response3 = zuki_client.chat.completions.create(
                            model="gemini-2.0-flash-thinking-exp-01-21",
                            messages=[{"role": "user", "content": prompt_parte3}],
                            max_tokens=4096,
                            temperature=0.7
                        )
                        
                        # Combinar os resultados
                        result = (response3.choices[0].message.content + "\n\n" + 
                                  response1.choices[0].message.content + "\n\n" + 
                                  response2.choices[0].message.content)
                        
                except Exception as api_error:
                    # Log detalhado do erro
                    logger.error(f"API Error: {str(api_error)}")
                    logger.error(traceback.format_exc())
                    
                    # Determinar o tipo de erro para uma mensagem mais informativa
                    error_msg = str(api_error).lower()
                    if "502: bad gateway" in error_msg:
                        logger.warning("Zuki API retornou 'Bad Gateway'. Tentando fallback para Gemini.")
                        use_gemini_fallback = True
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    elif "insufficient credits" in error_msg or ("credits" in error_msg and "available" in error_msg):
                        # Tentar fallback para Gemini
                        logger.info("Detectado erro de cr√©ditos insuficientes, tentando fallback para Gemini")
                        use_gemini_fallback = True
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    elif "content filter" in error_msg or "blocked" in error_msg or "safety" in error_msg:
                        error = "O tema foi bloqueado pelo filtro de conte√∫do da API. Por favor, tente outro tema."
                    elif "rate limit" in error_msg or "quota" in error_msg:
                        error = "Limite de requisi√ß√µes da API atingido. Por favor, tente novamente em alguns minutos."
                    elif "context length" in error_msg or "too many tokens" in error_msg or "maximum token" in error_msg:
                        error = "O tema solicitado √© muito complexo ou extenso. Por favor, tente um tema mais espec√≠fico ou reduza o n√∫mero de partes."
                    elif "timeout" in error_msg or "deadline" in error_msg:
                        error = "A requisi√ß√£o excedeu o tempo limite. Por favor, tente novamente ou escolha um tema menos complexo."
                    elif "invalid" in error_msg and "character" in error_msg:
                        error = "O tema cont√©m caracteres inv√°lidos ou especiais. Por favor, simplifique o texto."
                    else:
                        # Se estiver em modo de desenvolvimento, mostrar o erro real
                        if settings.DEBUG:
                            error = f"Erro na API: {str(api_error)}"
                        else:
                            error = "Ocorreu um erro ao processar sua solicita√ß√£o. Por favor, tente novamente mais tarde."
                    
                    if not use_gemini_fallback:  # S√≥ renderizar se n√£o estiver usando fallback
                        logger.info(f"Mensagem de erro exibida: {error}")
                        return render(request, 'index.html', {
                            'error': error,
                            'tema': tema,
                            'num_partes': num_partes
                        })
            
            # Para temas muito complexos que podem resultar em respostas truncadas
            elif tema.lower() in ['intelig√™ncia artificial', 'inteligencia artificial', 'machine learning', 
                                 'deep learning', 'cloud computing', 'cybersecurity']:
                # Para temas complexos, vamos gerar cada parte separadamente para garantir completude
                try:
                    if use_gemini_fallback or not zuki_client:
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    else:
                        # Gerar introdu√ß√£o usando Zuki
                        intro_prompt = f"""Crie apenas a introdu√ß√£o para um guia de estudos sobre "{tema}" em {num_partes} partes.
Use esta formata√ß√£o:
- T√≠tulo principal como Heading 1 (#): "# {tema} em {num_partes} Partes"
- Subse√ß√µes como Heading 2 (##):
  - ## Contextualiza√ß√£o (2-3 par√°grafos)
  - ## Objetivos Gerais (4-5 compet√™ncias em lista)"""
                    
                        intro_response = zuki_client.chat.completions.create(
                            model="gemini-2.0-flash-thinking-exp-01-21",
                            messages=[{"role": "user", "content": intro_prompt}],
                            max_tokens=2048,
                            temperature=0.7
                        )
                    
                        result = intro_response.choices[0].message.content + "\n\n"
                    
                        # Gerar cada parte individualmente
                        for i in range(1, num_partes + 1):
                            parte_prompt = f"""Crie APENAS a parte {i} de um guia de estudos sobre "{tema}".
Use esta formata√ß√£o:
- T√≠tulo da parte como Heading 1 (#): "# Parte {i}: [Verbo + Substantivo] ‚Üí [Emoji] ([Dura√ß√£o])"
  Exemplos: "# Parte 1: Desvendando as Origens ‚Üí üë∂ (1.5h)" ou "# Parte 2: Analisando a Evolu√ß√£o ‚Üí üìà (2h)"
- **Objetivo de Aprendizagem:** (1 par√°grafo)
- **T√≥picos Principais:** (lista de 3-5 itens com descri√ß√µes)
- **Conceitos-chave:** (lista de termos)
- **Pergunta de Reflex√£o:** (quest√£o instigante)

IMPORTANTE: Crie APENAS esta parte, sem introdu√ß√£o ou partes adicionais."""
                        
                            parte_response = zuki_client.chat.completions.create(
                                model="gemini-2.0-flash-thinking-exp-01-21",
                                messages=[{"role": "user", "content": parte_prompt}],
                                max_tokens=2048,
                                temperature=0.7
                            )
                        
                            result += parte_response.choices[0].message.content + "\n\n"
                    
                        # Gerar conclus√£o
                        conclusion_prompt = f"""Crie apenas a conclus√£o para um guia de estudos sobre "{tema}" em {num_partes} partes.
Use esta formata√ß√£o:
- T√≠tulo como Heading 1 (#): "# Conclus√£o"
Sintetize a progress√£o do conhecimento atrav√©s das partes e explique como elas se integram."""
                    
                        conclusion_response = zuki_client.chat.completions.create(
                            model="gemini-2.0-flash-thinking-exp-01-21",
                            messages=[{"role": "user", "content": conclusion_prompt}],
                            max_tokens=2048,
                            temperature=0.7
                        )
                    
                        result += conclusion_response.choices[0].message.content
                        
                except Exception as api_error:
                    # Log detalhado do erro
                    logger.error(f"API Error: {str(api_error)}")
                    logger.error(traceback.format_exc())
                    
                    # Determinar o tipo de erro para uma mensagem mais informativa
                    error_msg = str(api_error).lower()
                    if "502: bad gateway" in error_msg:
                        logger.warning("Zuki API retornou 'Bad Gateway'. Tentando fallback para Gemini.")
                        use_gemini_fallback = True
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    elif "insufficient credits" in error_msg or ("credits" in error_msg and "available" in error_msg):
                        # Tentar fallback para Gemini
                        logger.info("Detectado erro de cr√©ditos insuficientes, tentando fallback para Gemini")
                        use_gemini_fallback = True
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    elif "content filter" in error_msg or "blocked" in error_msg or "safety" in error_msg:
                        error = "O tema foi bloqueado pelo filtro de conte√∫do da API. Por favor, tente outro tema."
                    elif "rate limit" in error_msg or "quota" in error_msg:
                        error = "Limite de requisi√ß√µes da API atingido. Por favor, tente novamente em alguns minutos."
                    elif "context length" in error_msg or "too many tokens" in error_msg or "maximum token" in error_msg:
                        error = "O tema solicitado √© muito complexo ou extenso. Por favor, tente um tema mais espec√≠fico ou reduza o n√∫mero de partes."
                    elif "timeout" in error_msg or "deadline" in error_msg:
                        error = "A requisi√ß√£o excedeu o tempo limite. Por favor, tente novamente ou escolha um tema menos complexo."
                    elif "invalid" in error_msg and "character" in error_msg:
                        error = "O tema cont√©m caracteres inv√°lidos ou especiais. Por favor, simplifique o texto."
                    else:
                        # Se estiver em modo de desenvolvimento, mostrar o erro real
                        if settings.DEBUG:
                            error = f"Erro na API: {str(api_error)}"
                        else:
                            error = "Ocorreu um erro ao processar sua solicita√ß√£o. Por favor, tente novamente mais tarde."
                    
                    if not use_gemini_fallback:  # S√≥ renderizar se n√£o estiver usando fallback
                        logger.info(f"Mensagem de erro exibida: {error}")
                        return render(request, 'index.html', {
                            'error': error,
                            'tema': tema,
                            'num_partes': num_partes
                        })
            else:
                # Para poucos t√≥picos, usar abordagem normal
                prompt = generate_prompt(tema, num_partes)
                
                try:
                    logger.info(f"Enviando prompt para a API: tema='{tema}', num_partes={num_partes}")
                    
                    if use_gemini_fallback or not zuki_client:
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    else:
                        # Usar Zuki
                        response = zuki_client.chat.completions.create(
                            model="gemini-2.0-flash-thinking-exp-01-21",
                            messages=[{"role": "user", "content": prompt}],
                            max_tokens=8192,
                            temperature=0.7
                        )
                        
                        result = response.choices[0].message.content
                        logger.info(f"Resposta recebida da API Zuki com {len(result) if result else 0} caracteres")
                    
                except Exception as api_error:
                    # Log detalhado do erro
                    logger.error(f"API Error: {str(api_error)}")
                    logger.error(traceback.format_exc())
                    
                    # Determinar o tipo de erro para uma mensagem mais informativa
                    error_msg = str(api_error).lower()
                    if "502: bad gateway" in error_msg:
                        logger.warning("Zuki API retornou 'Bad Gateway'. Tentando fallback para Gemini.")
                        use_gemini_fallback = True
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    elif "insufficient credits" in error_msg or ("credits" in error_msg and "available" in error_msg):
                        # Tentar fallback para Gemini
                        logger.info("Detectado erro de cr√©ditos insuficientes, tentando fallback para Gemini")
                        use_gemini_fallback = True
                        return process_with_gemini()  # Importante: retornar a resposta diretamente
                    elif "content filter" in error_msg or "blocked" in error_msg or "safety" in error_msg:
                        error = "O tema foi bloqueado pelo filtro de conte√∫do da API. Por favor, tente outro tema."
                    elif "rate limit" in error_msg or "quota" in error_msg:
                        error = "Limite de requisi√ß√µes da API atingido. Por favor, tente novamente em alguns minutos."
                    elif "context length" in error_msg or "too many tokens" in error_msg or "maximum token" in error_msg:
                        error = "O tema solicitado √© muito complexo ou extenso. Por favor, tente um tema mais espec√≠fico ou reduza o n√∫mero de partes."
                    elif "timeout" in error_msg or "deadline" in error_msg:
                        error = "A requisi√ß√£o excedeu o tempo limite. Por favor, tente novamente ou escolha um tema menos complexo."
                    elif "invalid" in error_msg and "character" in error_msg:
                        error = "O tema cont√©m caracteres inv√°lidos ou especiais. Por favor, simplifique o texto."
                    else:
                        # Se estiver em modo de desenvolvimento, mostrar o erro real
                        if settings.DEBUG:
                            error = f"Erro na API: {str(api_error)}"
                        else:
                            error = "Ocorreu um erro ao processar sua solicita√ß√£o. Por favor, tente novamente mais tarde."
                    
                    if not use_gemini_fallback:  # S√≥ renderizar se n√£o estiver usando fallback
                        logger.info(f"Mensagem de erro exibida: {error}")
                        return render(request, 'index.html', {
                            'error': error,
                            'tema': tema,
                            'num_partes': num_partes,
                            'has_content': False,
                            'app_title': 'Chunkify',
                            'used_fallback': use_gemini_fallback
                        })
            
            # Converter markdown para HTML
            if result:
                try:
                    # Usar safe para garantir que o HTML n√£o √© escapado
                    html_result = mark_safe(markdown.markdown(
                        result, 
                        extensions=['extra', 'fenced_code', 'tables', 'nl2br', 'sane_lists']
                    ))
                    
                    # Verificar se temos um resultado v√°lido
                    if not html_result or not str(html_result).strip():
                        logger.warning("Resultado HTML vazio ou inv√°lido")
                        error = "Erro: N√£o foi poss√≠vel gerar o conte√∫do solicitado. Resultado vazio."
                except Exception as md_error:
                    logger.error(f"Erro na convers√£o Markdown: {str(md_error)}")
                    error = "Erro na formata√ß√£o do conte√∫do. Por favor, tente novamente."
                    
    except requests.exceptions.HTTPError as http_error:
        logger.error(f"HTTP Error: {str(http_error)}")
        error = "Erro de conex√£o com o servi√ßo de IA. Por favor, tente novamente mais tarde."
    except requests.exceptions.ConnectionError as conn_error:
        logger.error(f"Connection Error: {str(conn_error)}")
        error = "N√£o foi poss√≠vel conectar ao servi√ßo de IA. Verifique sua conex√£o de internet."
    except requests.exceptions.Timeout as timeout_error:
        logger.error(f"Timeout Error: {str(timeout_error)}")
        error = "A requisi√ß√£o excedeu o tempo limite. Por favor, tente novamente mais tarde."
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        logger.error(traceback.format_exc())
        if settings.DEBUG:
            error = f"Erro inesperado: {str(e)}"
        else:
            error = "Ops! N√£o conseguimos processar esse tema. Por favor, tente novamente mais tarde."
    
    context = {
        'result': result,
        'html_result': html_result,
        'error': error,
        'tema': tema,
        'num_partes': num_partes,
        'has_content': bool(html_result),
        'app_title': 'Chunkify',  # Alterado de 'ChunkMaster' para 'Chunkify'
        'used_fallback': use_gemini_fallback  # Adicionar indicador de fallback para UI
    }
    
    return render(request, 'index.html', context)
